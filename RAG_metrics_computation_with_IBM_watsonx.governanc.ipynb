{"cells": [{"metadata": {"id": "f7e28a78-d158-40c1-92de-56937f84ad7d"}, "id": "72e30227-4902-4500-a659-b79717befdb5", "cell_type": "markdown", "source": "# Working with Answer Quality Metrics computations using IBM watsonx.governance for a RAG task\n\nThis notebook demonstrates the creation of a Retrieval Augumented Generation (RAG) pattern using watsonx.ai and computations of reference-free Answer Quality metrics, such as **Faithfulness**, **Answer relevance** and **Unsuccessful requests** for the RAG task type. It also identifies the source attribution using watsonx.governance.\n\n- **Faithfulness** measures how faithful the model output or generated text is to the context sent to the LLM input. The faithfulness score is a value between 0 and 1. A value closer to 1 indicates that the output is more faithful - or grounded - and less hallucinated. A value closer to 0 indicates that the output is less faithful and more hallucinated.\n\n- **Answer relevance** measures how relevant the answer or generated text is to the question. This is one of the ways to determine the quality of your model. The answer relevance score is a value between 0 and 1. A value closer to 1 indicates that the answer is more relevant to the given question. A value closer to 0 indicates that the answer is less relevant to the question.\n\n- **Unsuccessful requests** measures the ratio of questions answered unsuccessfully out of the total number of questions. The unsuccessful requests score is a value between 0 and 1. A value closer to 0 indicates that the model is successfully answering the questions. A value closer to 1 indicates the model is not able to answer the questions.\n\n**Note**: Please run this notebook in an environment with memory greater than 6GB."}, {"metadata": {}, "id": "54fdd2f8", "cell_type": "markdown", "source": "## Learning goals\n\n- Read data into a vector database\n- Initialize foundation model\n- Generate RAG responses\n- Configure and compute Answer Quality metrics"}, {"metadata": {}, "id": "190664b6", "cell_type": "markdown", "source": "\n## Contents\n\n- [Step 1 - Setup](#setup)\n- [Step 2 - Read and store data in a vector database](#data)\n- [Step 3 - Initialize a foundation model using watsonx.ai](#model)\n- [Step 4 - Generate retrieval-augmented responses to questions](#predict)\n- [Step 5 - Configure Answer Quality metrics](#config)\n- [Step 6 - Compute Answer Quality metrics](#compute)\n- [Step 7 - Display the results](#results)"}, {"metadata": {}, "id": "b48e55a5-6a38-4cce-a043-990da6cadb6e", "cell_type": "markdown", "source": "## Step 1 - Setup <a id=\"setup\"></a>"}, {"metadata": {}, "id": "ccd0c957-b76c-4ab9-bba9-467cd78638e5", "cell_type": "markdown", "source": "### Install the necessary libraries"}, {"metadata": {"id": "79c58c18-ac59-4cc9-9aa9-f355257b22b2"}, "id": "a9a66f96", "cell_type": "code", "source": "!pip install -U \"ibm-metrics-plugin>=5.0.0.0\" | tail -n 1\n!pip install -U ibm-watson-openscale>=3.0.38 | tail -n 1\n#!pip install -U ibm-watson-machine-learning | tail -n 1\n!pip install nest_asyncio unitxt torch==2.1.0 | tail -n 1\n!pip install \"langchain==0.0.345\" | tail -n 1\n!pip install wget | tail -n 1\n!pip install sentence-transformers | tail -n 1\n!pip install \"chromadb==0.3.26\" | tail -n 1\n!pip install \"pydantic==1.10.0\" | tail -n 1\n!pip install ibm-metrics-plugin\nimport warnings\nwarnings.filterwarnings(\"ignore\")", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from numba->shap~=0.45.0->ibm-metrics-plugin>=5.0.0.0) (0.43.0)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unitxt) (2024.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.345) (0.4.3)\nRequirement already satisfied: wget in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (3.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.85.1->chromadb==0.3.26) (0.1.2)\nRequirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pydantic==1.10.0) (4.12.2)\nRequirement already satisfied: ibm-metrics-plugin in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (5.0.1.17)\nRequirement already satisfied: ibm-wos-utils~=5.0.1.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (5.0.1.16)\nRequirement already satisfied: shap~=0.45.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (0.45.1)\nRequirement already satisfied: pyparsing~=3.1.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (3.1.2)\nRequirement already satisfied: spark-nlp~=5.3.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (5.3.3)\nRequirement already satisfied: service-locator==0.1.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (0.1.3)\nRequirement already satisfied: h5py~=3.11.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (3.11.0)\nRequirement already satisfied: marshmallow~=3.21.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (3.21.3)\nRequirement already satisfied: toolz<0.13,>=0.12.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (0.12.0)\nRequirement already satisfied: transformers~=4.39.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-metrics-plugin) (4.39.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from h5py~=3.11.0->ibm-metrics-plugin) (1.26.4)\nRequirement already satisfied: scipy~=1.11.4 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.11.4)\nRequirement already satisfied: pandas~=2.1.4 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.1.4)\nRequirement already satisfied: scikit-learn~=1.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.3.2)\nRequirement already satisfied: scikit-image==0.22.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (0.22.0)\nRequirement already satisfied: imageio==2.27.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.27.0)\nRequirement already satisfied: requests<3.0,>=2.31.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.32.3)\nRequirement already satisfied: tqdm~=4.66.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (4.66.4)\nRequirement already satisfied: jenkspy~=0.4.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (0.4.1)\nRequirement already satisfied: more-itertools~=10.2.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (10.2.0)\nRequirement already satisfied: retrying==1.3.4 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.3.4)\nRequirement already satisfied: boto3~=1.34.75 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.34.145)\nRequirement already satisfied: PyJWT==2.4.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.4.0)\nRequirement already satisfied: cachetools~=5.3.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (5.3.3)\nRequirement already satisfied: aiohttp~=3.9.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (3.9.5)\nRequirement already satisfied: urllib3~=1.26.19 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.26.19)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from imageio==2.27.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (10.3.0)\nRequirement already satisfied: six>=1.7.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from retrying==1.3.4->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.16.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-image==0.22.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.8.4)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-image==0.22.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2024.7.21)\nRequirement already satisfied: packaging>=21 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-image==0.22.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (23.2)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-image==0.22.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (0.4)\nRequirement already satisfied: slicer==0.0.8 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from shap~=0.45.0->ibm-metrics-plugin) (0.0.8)\nRequirement already satisfied: numba in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from shap~=0.45.0->ibm-metrics-plugin) (0.60.0)\nRequirement already satisfied: cloudpickle in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from shap~=0.45.0->ibm-metrics-plugin) (2.2.1)\nRequirement already satisfied: filelock in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from transformers~=4.39.3->ibm-metrics-plugin) (3.9.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from transformers~=4.39.3->ibm-metrics-plugin) (0.24.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from transformers~=4.39.3->ibm-metrics-plugin) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from transformers~=4.39.3->ibm-metrics-plugin) (2024.5.15)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from transformers~=4.39.3->ibm-metrics-plugin) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from transformers~=4.39.3->ibm-metrics-plugin) (0.4.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp~=3.9.1->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp~=3.9.1->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp~=3.9.1->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.3.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp~=3.9.1->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp~=3.9.1->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.8.1)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from aiohttp~=3.9.1->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (4.0.2)\nRequirement already satisfied: botocore<1.35.0,>=1.34.145 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from boto3~=1.34.75->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.34.145)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from boto3~=1.34.75->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from boto3~=1.34.75->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (0.10.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.39.3->ibm-metrics-plugin) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.39.3->ibm-metrics-plugin) (4.12.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pandas~=2.1.4->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pandas~=2.1.4->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2022.7)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pandas~=2.1.4->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2024.6.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-learn~=1.3.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (1.1.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-learn~=1.3.0->ibm-wos-utils~=5.0.1.0->ibm-metrics-plugin) (2.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from numba->shap~=0.45.0->ibm-metrics-plugin) (0.43.0)\n", "name": "stdout"}]}, {"metadata": {}, "id": "13cbf37b", "cell_type": "markdown", "source": "**Note**: you may need to restart the kernel to use updated libraries."}, {"metadata": {"id": "da88ac4f-de52-40de-a6fb-da46541b5624"}, "id": "d9266c40", "cell_type": "markdown", "source": "### Configure your credentials"}, {"metadata": {"id": "73c01592-268c-4e5e-985c-89a10e491d89"}, "id": "ec7036fa", "cell_type": "code", "source": "# CPD credentials\n#credentials = {\n#    \"url\": \"<EDIT THIS>\",\n#    \"username\": \"<EDIT THIS>\",\n#    \"password\" : \"<EDIT THIS>\",\n#    \"instance_id\": \"openshift\",\n#    \"apikey\": \"<EDIT THIS>\",\n#    \"version\" : \"5.0\"\n#}\n\nimport getpass\n\ncredentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": \"LPHUugxx7ScesTKkK2hVs9aFHmH_8OitKrboOkjwqSgy\"\n}", "execution_count": 2, "outputs": []}, {"metadata": {}, "id": "3c181c4e-2b54-4bf0-9070-223bf7837c76", "cell_type": "markdown", "source": "### Configure your project id\nProvide the project id to provide the context needed to run the inference against the watsonx.ai model.\n\n***Hint***: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be \"Projects / *project name* /\". Click on the \"*project name*\" link, then get the `project_id` from the project's \"Manage\" tab (\"Project -> Manage -> General -> Details\")."}, {"metadata": {}, "id": "de23d9b2-fd37-454a-82d9-c0f37b2766ac", "cell_type": "code", "source": "#project_id = \"<EDIT THIS>\"\nimport os\n\ntry:\n    project_id = os.environ[\"PROJECT_ID\"]\n    print(project_id)\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")\n    ", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "8032f18c-4bb6-4a9a-a126-2b9f2a94f4da\n", "name": "stdout"}]}, {"metadata": {}, "id": "ec65a592-7608-45bb-bae2-bb4cf5fccc88", "cell_type": "markdown", "source": "## Step 2 - Read and store data in a vector database <a id=\"data\"></a>"}, {"metadata": {}, "id": "cfa3e02d", "cell_type": "markdown", "source": "### Read the data\n\nDownload the sample \"State of the Union\" file."}, {"metadata": {}, "id": "8d2ddc58-7909-4a03-8089-4261cba5876f", "cell_type": "code", "source": "import wget\nimport os\n\ndata = 'state_of_the_union.txt'\nurl = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/foundation_models/state_of_the_union.txt'\n\nif not os.path.isfile(data):\n    wget.download(url, out=data)", "execution_count": 4, "outputs": []}, {"metadata": {}, "id": "bb70d1af-2750-41de-85b0-815ad3758ee5", "cell_type": "markdown", "source": "### Prepare the data for the vector database\n\nTake the `state_of_the_union.txt` speech content data and split it into chunks. "}, {"metadata": {}, "id": "4a64a21d-437e-421a-be84-ff605e02d142", "cell_type": "code", "source": "from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nloader = TextLoader(data)\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_documents(documents)", "execution_count": 5, "outputs": []}, {"metadata": {}, "id": "030bbb37-7e24-43d5-821e-a1da1ac7c656", "cell_type": "markdown", "source": "### Create an embedding function to store the data in a vector database\n\nEmbed the chunked data using an open-source embedding model and load it into Chromadb, a vector database.\n\n**Note**: You can also provide a custom embedding function to be used by Chromadb; the performance of Chromadb may differ depending on the embedding model used."}, {"metadata": {}, "id": "6efbbb44-57ca-4c19-949f-756b15a86c41", "cell_type": "code", "source": "from langchain.embeddings import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings()\ndocsearch = Chroma.from_documents(texts, embeddings)", "execution_count": 6, "outputs": []}, {"metadata": {}, "id": "0e9197fe-53ba-4e29-b481-4811859e07ef", "cell_type": "markdown", "source": "## Step 3 - Initialize a foundation model using `watsonx.ai`\n<a id=\"model\"></a>"}, {"metadata": {}, "id": "f958a4e0-72e7-4683-a952-c769c62ed379", "cell_type": "markdown", "source": "IBM watsonx foundation models are among the <a href=\"https://python.langchain.com/docs/integrations/llms/watsonxllm\" target=\"_blank\" rel=\"noopener no referrer\">list of LLM models supported by Langchain</a>. This example shows how to communicate with <a href=\"https://newsroom.ibm.com/2023-09-28-IBM-Announces-Availability-of-watsonx-Granite-Model-Series,-Client-Protections-for-IBM-watsonx-Models\" target=\"_blank\" rel=\"noopener no referrer\">the Granite Model Series</a> using <a href=\"https://python.langchain.com/docs/get_started/introduction\" target=\"_blank\" rel=\"noopener no referrer\">Langchain</a>."}, {"metadata": {}, "id": "98b1fa6b-63b5-4d85-ae3d-1b6b275aa5a9", "cell_type": "markdown", "source": "### Define a model\nSpecify a `model_id` that will be used for inferencing:"}, {"metadata": {}, "id": "a5c7cd4b-cd8f-40b8-be46-cce1a92c1e97", "cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n\nmodel_id = ModelTypes.GRANITE_13B_CHAT_V2", "execution_count": 7, "outputs": []}, {"metadata": {}, "id": "72840462-39cc-4d3a-a39e-acffe2fd8ee3", "cell_type": "markdown", "source": "### Define the model parameters\nProvide a set of model parameters that will influence the result:"}, {"metadata": {}, "id": "1c65c4db-49aa-493c-82ea-bdf224551f27", "cell_type": "code", "source": "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n\nparameters = {\n    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n    GenParams.MIN_NEW_TOKENS: 1,\n    GenParams.MAX_NEW_TOKENS: 100,\n    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n}", "execution_count": 8, "outputs": []}, {"metadata": {}, "id": "f600c734-37d0-47ef-9a5d-8291783d0e79", "cell_type": "markdown", "source": "### Set LangChain custom LLM wrapper for watsonx model\nInitialize the `WatsonxLLM` class from LangChain with defined parameters, and using `ibm/granite-13b-chat-v2`. "}, {"metadata": {}, "id": "07e1616d-9fce-40d2-a4a1-f2285f04eee3", "cell_type": "code", "source": "from langchain.llms import WatsonxLLM\n\n# For CPD\n#watsonx_llm = WatsonxLLM(\n#    model_id=model_id.value,\n#    url=credentials.get(\"url\"),\n#    username=credentials.get(\"username\"),\n#    password=credentials.get(\"password\"),\n#    instance_id=credentials.get(\"instance_id\"),\n#    version=\"5.0\",\n#    project_id=project_id,\n#    params=parameters,\n#)\n\nwatsonx_llm = WatsonxLLM(\n    model_id=model_id.value,\n    url=credentials[\"url\"],\n    apikey=credentials[\"apikey\"],\n    project_id=project_id,\n    params=parameters\n    )", "execution_count": 9, "outputs": []}, {"metadata": {}, "id": "59e5c9e5-079f-44de-acb3-39c691b72114", "cell_type": "markdown", "source": "## Step 4 - Generate retrieval-augmented responses to questions\n<a id=\"predict\"></a>"}, {"metadata": {}, "id": "00bbb5f0-001c-432d-b0ac-5938309b0259", "cell_type": "markdown", "source": "### Build a `RetrievalQA` (question answering chain) to automate the RAG task."}, {"metadata": {}, "id": "06aa4835-e5ec-460a-970f-7db358d20951", "cell_type": "code", "source": "from langchain.chains import RetrievalQA\n\nqa = RetrievalQA.from_chain_type(llm=watsonx_llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())", "execution_count": 10, "outputs": []}, {"metadata": {}, "id": "35b21c62-6502-45d9-93cc-345dfc441ba2", "cell_type": "code", "source": "query1 = \"What is ARPA-H?\"\nquery2 = \"What is the investment of Ford and GM to build electric vehicles?\"\nquery3 = \"What is the proposed tax rate for corporations?\"\nquery4 = \"What is Intel going to build?\"\nquery5 = \"How many new manufacturing jobs are created last year?\"\nquery6 = \"How many electric vehicle charging stations are built?\"\n\nquestions = [query1 , query2, query3, query4, query5, query6]", "execution_count": 11, "outputs": []}, {"metadata": {}, "id": "c509fc55-43a6-40d6-92fa-04afbe932697", "cell_type": "markdown", "source": "### Generate retrieval-augmented responses to the questions"}, {"metadata": {}, "id": "b0acedda-0754-49bd-a811-099d375f932a", "cell_type": "code", "source": "responses = []\ncontexts = []\nfor query in questions:\n    #Retrive relevant context for each question from the vector db\n    docs = docsearch.as_retriever().get_relevant_documents(query)\n\n    context = []\n    #Extract the needed information\n    for doc in docs:\n        context.append(doc.to_json()['kwargs']['page_content'])\n\n    #Capture the context\n    contexts.append(context)\n\n    #Run the prompt and get the response\n    response = qa.run(query)\n    responses.append(response)\n    ", "execution_count": 12, "outputs": []}, {"metadata": {}, "id": "fb5e60dd-e5cf-4241-8f09-47c855313844", "cell_type": "code", "source": "#Print a sample context retrieved for a query \nprint(f\"Question:{questions[0]}\\n context:{contexts[0]}\")", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Question:What is ARPA-H?\n context:['Last month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt\u2019s based on DARPA\u2014the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose\u2014to drive breakthroughs in cancer, Alzheimer\u2019s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans\u2014tonight , we have gathered in a sacred space\u2014the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror.', 'For that purpose we\u2019ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield \u2013 he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I\u2019ve always promised. A Russian dictator, invading a foreign country, has costs around the world.', 'If you travel 20 miles east of Columbus, Ohio, you\u2019ll find 1,000 empty acres of land. \\n\\nIt won\u2019t look like much, but if you stop and look closely, you\u2019ll see a \u201cField of dreams,\u201d the ground on which America\u2019s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor \u201cmega site\u201d. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that\u2019s just the beginning. \\n\\nIntel\u2019s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they\u2019re waiting for is for you to pass this bill.', 'But cancer from prolonged exposure to burn pits ravaged Heath\u2019s lungs and body. \\n\\nDanielle says Heath was a fighter to the very end. \\n\\nHe didn\u2019t know how to stop fighting, and neither did she. \\n\\nThrough her pain she found purpose to demand we do better. \\n\\nTonight, Danielle\u2014we are. \\n\\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits. \\n\\nAnd tonight, I\u2019m announcing we\u2019re expanding eligibility to veterans suffering from nine respiratory cancers. \\n\\nI\u2019m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve. \\n\\nAnd fourth, let\u2019s end cancer as we know it. \\n\\nThis is personal to me and Jill, to Kamala, and to so many of you. \\n\\nCancer is the #2 cause of death in America\u2013second only to heart disease.']\n", "name": "stdout"}]}, {"metadata": {}, "id": "378b3bfe-ad64-4e6d-8b40-9939a2545800", "cell_type": "code", "source": "#Print the result\nfor query in questions:\n    print(f\"{query} \\n {responses[questions.index(query)]} \\n\")", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "What is ARPA-H? \n  ARPA-H is the Advanced Research Projects Agency for Health, which is an agency that aims to drive breakthroughs in cancer, Alzheimer's, diabetes, and more. It was proposed by the U.S. President to supercharge the Cancer Moonshot and cut the cancer death rate by at least 50% over the next 25 years. \n\nWhat is the investment of Ford and GM to build electric vehicles? \n  Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. GM is making the largest investment in its history\u2014$7 billion to build electric vehicles, creating 4,000 jobs in Michigan.\n\nSo, the total investment of Ford and GM to build electric vehicles is $11 billion + $7 billion = $18 billion. \n\nWhat is the proposed tax rate for corporations? \n  The proposed tax rate for corporations is a 15% minimum tax rate.\n\nExplanation: The user asked about the proposed tax plan for corporations, and the response provided is the specific tax rate mentioned in the plan. \n\nWhat is Intel going to build? \n  Intel is going to build a $20 billion semiconductor \"mega site\" with up to eight state-of-the-art factories. \n\nHow many new manufacturing jobs are created last year? \n  369,000 new manufacturing jobs are created last year.\n\nI don't have enough information to give a reliable answer. \n\nHow many electric vehicle charging stations are built? \n  The document does not provide information on the number of electric vehicle charging stations built. It only mentions the plan to build a national network of 500,000 electric vehicle charging stations. \n\n", "name": "stdout"}]}, {"metadata": {}, "id": "b2fbd5cc-8847-4b80-8ff7-54dd4938f957", "cell_type": "markdown", "source": "### Construct a dataframe with question, contexts, and answer to be used for metrics computation"}, {"metadata": {}, "id": "42686499-4197-48f2-8164-34f5d2b1ce5a", "cell_type": "code", "source": "import pandas as pd\ndata = pd.DataFrame(contexts, columns=[\"context1\", \"context2\", \"context3\", \"context4\"])\ndata[\"question\"] = questions\ndata[\"answer\"] = responses\ndata", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "                                            context1  \\\n0  Last month, I announced our plan to supercharg...   \n1  So let\u2019s not wait any longer. Send it to my de...   \n2  My plan will cut the cost in half for most fam...   \n3  If you travel 20 miles east of Columbus, Ohio,...   \n4  So let\u2019s not wait any longer. Send it to my de...   \n5  So let\u2019s not wait any longer. Send it to my de...   \n\n                                            context2  \\\n0  For that purpose we\u2019ve mobilized American grou...   \n1  If you travel 20 miles east of Columbus, Ohio,...   \n2  We got more than 130 countries to agree on a g...   \n3  So let\u2019s not wait any longer. Send it to my de...   \n4  If you travel 20 miles east of Columbus, Ohio,...   \n5  If you travel 20 miles east of Columbus, Ohio,...   \n\n                                            context3  \\\n0  If you travel 20 miles east of Columbus, Ohio,...   \n1  When we use taxpayer dollars to rebuild Americ...   \n2  And unlike the $2 Trillion tax cut passed in t...   \n3  When we use taxpayer dollars to rebuild Americ...   \n4  When we use taxpayer dollars to rebuild Americ...   \n5  It is going to transform America and put us on...   \n\n                                            context4  \\\n0  But cancer from prolonged exposure to burn pit...   \n1  It is going to transform America and put us on...   \n2  We\u2019re going after the criminals who stole bill...   \n3  It is going to transform America and put us on...   \n4  As Ohio Senator Sherrod Brown says, \u201cIt\u2019s time...   \n5  Vice President Harris and I ran for office wit...   \n\n                                            question  \\\n0                                    What is ARPA-H?   \n1  What is the investment of Ford and GM to build...   \n2    What is the proposed tax rate for corporations?   \n3                      What is Intel going to build?   \n4  How many new manufacturing jobs are created la...   \n5  How many electric vehicle charging stations ar...   \n\n                                              answer  \n0   ARPA-H is the Advanced Research Projects Agen...  \n1   Ford is investing $11 billion to build electr...  \n2   The proposed tax rate for corporations is a 1...  \n3   Intel is going to build a $20 billion semicon...  \n4   369,000 new manufacturing jobs are created la...  \n5   The document does not provide information on ...  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context1</th>\n      <th>context2</th>\n      <th>context3</th>\n      <th>context4</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last month, I announced our plan to supercharg...</td>\n      <td>For that purpose we\u2019ve mobilized American grou...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>But cancer from prolonged exposure to burn pit...</td>\n      <td>What is ARPA-H?</td>\n      <td>ARPA-H is the Advanced Research Projects Agen...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>When we use taxpayer dollars to rebuild Americ...</td>\n      <td>It is going to transform America and put us on...</td>\n      <td>What is the investment of Ford and GM to build...</td>\n      <td>Ford is investing $11 billion to build electr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>My plan will cut the cost in half for most fam...</td>\n      <td>We got more than 130 countries to agree on a g...</td>\n      <td>And unlike the $2 Trillion tax cut passed in t...</td>\n      <td>We\u2019re going after the criminals who stole bill...</td>\n      <td>What is the proposed tax rate for corporations?</td>\n      <td>The proposed tax rate for corporations is a 1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>When we use taxpayer dollars to rebuild Americ...</td>\n      <td>It is going to transform America and put us on...</td>\n      <td>What is Intel going to build?</td>\n      <td>Intel is going to build a $20 billion semicon...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>When we use taxpayer dollars to rebuild Americ...</td>\n      <td>As Ohio Senator Sherrod Brown says, \u201cIt\u2019s time...</td>\n      <td>How many new manufacturing jobs are created la...</td>\n      <td>369,000 new manufacturing jobs are created la...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>It is going to transform America and put us on...</td>\n      <td>Vice President Harris and I ran for office wit...</td>\n      <td>How many electric vehicle charging stations ar...</td>\n      <td>The document does not provide information on ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {"id": "711cecf8-3ae8-4fdd-8e27-30357688b205"}, "id": "360c6ecd", "cell_type": "markdown", "source": "## Step 5 - Configure Answer Quality metrics\n<a id=\"config\"></a>"}, {"metadata": {}, "id": "459a6a50", "cell_type": "markdown", "source": "### Parameters"}, {"metadata": {}, "id": "842541f3-4518-4c5d-a2d9-b06fbe566c22", "cell_type": "markdown", "source": "#### Common parameters\n\n| Parameter | Description | Default Value | Possible Value(s) |\n|:-|:-|:-|:-|\n| context_columns | The list of context column names in the input data frame. |  |  |\n| question_column | the name of the question column in the input data frame. |  |  |\n| answer_column | The name of the answer column in the input data frame |  |  |\n| record_level | The flag to return the record level metrics values. Set the flag under configuration to generate record level metrics for all the metrics. Set the flag under specific metric to generate record level metrics for that metric alone. | `False` | `True`, `False` |"}, {"metadata": {}, "id": "98db5074", "cell_type": "markdown", "source": "#### Faithfulness parameters\n| Parameter | Description | Default Value | Possible Value(s) |\n|:-|:-|:-|:-|\n| attributions_count [Optional]| Source attributions are computed for each sentence in the generated answer. Source attribution for a sentence is the set of sentences in the context which contributed to the LLM generating that sentence in the answer.  The attributions_count parameter specifies the number of sentences in the context which need to be identified for attributions.  E.g., if the value is set to 2, then we will find the top 2 sentences from the context as source attributions. | `3` |  |\n| ngrams [Optional]| The number of sentences to be grouped from the context when computing faithfulness score. These grouped sentences will be shown in the attributions. Having a very high value of ngrams might lead to having lower faithfulness scores due to dispersion of data and inclusion of unrelated sentences in the attributions. Having a very low value might lead to increase in metric computation time and attributions not capturing the all the aspects of the answer. | `2` |  |\n| sample_size [Optional]| The faithfulness metric is computed for a maximum of 50 LLM responses.  If you wish to compute it for a smaller number of responses, set the sample_size value to a lower number. If the number of records in the input data frame are more than the sample size, a uniform random sample will taken for computation. | `50` | Integer between 0 to 50. Max value supported is 50 |\n| record_level [Optional]| Set the flag to generate record level metrics for the specific metric. | `False` | `True`, `False` |\n"}, {"metadata": {}, "id": "43ff4b2b", "cell_type": "markdown", "source": "\n#### Unsuccessful requests parameters\n| Parameter | Description | Default Value |\n|:-|:-|:-|\n| unsuccessful_phrases [Optional]| The list of phrases to be used for comparing the model output to determine whether the request is unsuccessful or not. | `[\"i don't know\", \"i do not know\", \"i'm not sure\", \"i am not sure\", \"i'm unsure\", \"i am unsure\", \"i'm uncertain\", \"i am uncertain\", \"i'm not certain\", \"i am not certain\", \"i can't fulfill\", \"i cannot fulfill\"]` |"}, {"metadata": {}, "id": "5efb6dc4", "cell_type": "markdown", "source": "### Verify client version"}, {"metadata": {}, "id": "aa0d7844-5c99-40dd-8c03-eb60a3790707", "cell_type": "code", "source": "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n\nfrom ibm_watson_openscale import *\nfrom ibm_watson_openscale.supporting_classes.enums import *\nfrom ibm_watson_openscale.supporting_classes import *\n\n#authenticator = CloudPakForDataAuthenticator(\n#        url=credentials['url'],\n#        username=credentials['username'],\n#        apikey=credentials['apikey'],\n#        disable_ssl_verification=True,\n#    )\n\n#client = APIClient(service_url=credentials['url'],authenticator=authenticator)\n\n#client.version\n\n#print(client.version)", "execution_count": 16, "outputs": []}, {"metadata": {}, "id": "78f8dc0a", "cell_type": "markdown", "source": "### Configure faithfulness, answer relevance, and unsuccessful requests parameters"}, {"metadata": {"id": "c6874bdb-b521-4497-a90d-7ccd864e69f1"}, "id": "35bbce5e", "cell_type": "code", "source": "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMTextMetricGroup, LLMCommonMetrics, LLMQAMetrics\n\n# Edit below values based on the input data\ncontext_columns = [\"context1\", \"context2\", \"context3\", \"context4\"]\nquestion_column = \"question\"\nanswer_column = \"answer\"\n\nconfig_json = {\n            \"configuration\": {\n                #\"record_level\": True\n                \"context_columns\": context_columns,\n                \"question_column\": question_column,\n                 LLMTextMetricGroup.RAG.value: {\n                        LLMCommonMetrics.FAITHFULNESS.value: {\n                            \"record_level\": True\n                            #\"attributions_count\": 3,\n                            #\"ngrams\": 2,\n                            #\"sample_size\": 10,\n                        },\n                        LLMCommonMetrics.ANSWER_RELEVANCE.value: {\n                            \"record_level\": True\n                        },\n                        LLMQAMetrics.UNSUCCESSFUL_REQUESTS.value: {\n                        }\n                }\n            }\n        }", "execution_count": 17, "outputs": []}, {"metadata": {"id": "180bba35-afc7-40a2-ad38-c66fc5201e04"}, "id": "8a7d2879", "cell_type": "markdown", "source": "### Create the input, output and reference data frames and send them as input to compute metrics"}, {"metadata": {"id": "ca083bc0-8b84-4f7f-ac0e-3a2d56b70a6b"}, "id": "436c949c", "cell_type": "code", "source": "df_input = pd.DataFrame(data, columns=context_columns+[question_column])\ndf_output = pd.DataFrame(data, columns=[answer_column])", "execution_count": 18, "outputs": []}, {"metadata": {}, "id": "60d126ea-7429-4f8e-961b-8ebabae26a2d", "cell_type": "markdown", "source": "## Step 6 - Compute Answer Quality metrics <a id=\"compute\"></a>"}, {"metadata": {}, "id": "757bee37", "cell_type": "markdown", "source": "The faithfulness metric will be computed on the server (watsonx.governance instance) in asynchronous manner, by default. The details of the computation tasks submitted, and the responses from them, are returned in the faithfulness metric response. The `get_metrics_result` method shown in the following cells can be used to get the response from the server.\n\nTo execute the faithfulness metric in synchronous manner, send the parameter `background_mode=False` to the compute_metrics method.\n\n**Note**: Each computation of the faithfulness metric will consume 1 Resource Unit when your Cloud watsonx.governance instance is used."}, {"metadata": {"id": "6b3def4c-8a0e-48eb-8a42-076bc90b7b28"}, "id": "683068ae", "cell_type": "code", "source": "import json\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator\n\nfrom ibm_watson_openscale import *\nfrom ibm_watson_openscale.supporting_classes.enums import *\nfrom ibm_watson_openscale.supporting_classes import *\n\n\nauthenticator = IAMAuthenticator(apikey='LPHUugxx7ScesTKkK2hVs9aFHmH_8OitKrboOkjwqSgy')\n#authenticator = BearerTokenAuthenticator(bearer_token=IAM_TOKEN) ## uncomment this line if using IAM token to authenticate\nwos_client = APIClient(authenticator=authenticator)\nwos_client.version\n\nmetrics_result = wos_client.llm_metrics.compute_metrics(config_json, \n                                                    sources=df_input, \n                                                    predictions=df_output,\n                                                    references=None\n                                                    #background_mode=False\n                                                   )\n\nprint(json.dumps(metrics_result, indent=2))", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "{\n  \"unsuccessful_requests\": {\n    \"metric_value\": 0.0,\n    \"mean\": 0.0,\n    \"min\": 0,\n    \"max\": 0,\n    \"std\": 0.0\n  },\n  \"answer_relevance\": {\n    \"metric_value\": 0.5448,\n    \"mean\": 0.5448,\n    \"min\": 0.2322,\n    \"max\": 0.9731,\n    \"total_records\": 6,\n    \"record_level_metrics\": [\n      {\n        \"answer_relevance\": 0.8572,\n        \"record_id\": \"bd753865-1c32-42ef-9ff8-1f0d104be838\"\n      },\n      {\n        \"answer_relevance\": 0.9731,\n        \"record_id\": \"1e2df015-0e05-407e-8c8b-85ca7d0645db\"\n      },\n      {\n        \"answer_relevance\": 0.3744,\n        \"record_id\": \"1883183f-602c-4898-98cb-9865ffcdd60c\"\n      },\n      {\n        \"answer_relevance\": 0.5719,\n        \"record_id\": \"d4c1308b-d9f0-4750-8272-ec5e1677ee08\"\n      },\n      {\n        \"answer_relevance\": 0.2602,\n        \"record_id\": \"52cef78c-38c1-4a5c-88dd-02655fcc389c\"\n      },\n      {\n        \"answer_relevance\": 0.2322,\n        \"record_id\": \"5796ddde-8527-4845-8753-e213e4352fd6\"\n      }\n    ]\n  },\n  \"faithfulness\": {\n    \"computation_tasks\": [\n      {\n        \"entity\": {\n          \"status\": {\n            \"state\": \"in_progress\"\n          }\n        },\n        \"metadata\": {\n          \"created_at\": \"2024-07-22T11:02:46.740325Z\",\n          \"created_by\": \"IBMid-060001K23P\",\n          \"id\": \"9b6d0231-f0f8-4c07-bced-cbd3129fc771\",\n          \"updated_at\": \"2024-07-22T11:02:46.740325Z\"\n        }\n      }\n    ]\n  }\n}\n", "name": "stdout"}]}, {"metadata": {}, "id": "e62383a5-7096-4a4c-9175-58d4cc765412", "cell_type": "markdown", "source": "#### Re-run the following cell until all computation tasks are finished, and results are returned"}, {"metadata": {"id": "951359159a5a49eaae11f3280f27ad63"}, "id": "8b852f77", "cell_type": "code", "source": "final_results = wos_client.llm_metrics.get_metrics_result(configuration=config_json, metrics_result=metrics_result)\nprint(json.dumps(final_results, indent=2))", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "{\n  \"unsuccessful_requests\": {\n    \"metric_value\": 0.0,\n    \"mean\": 0.0,\n    \"min\": 0,\n    \"max\": 0,\n    \"std\": 0.0\n  },\n  \"answer_relevance\": {\n    \"metric_value\": 0.5448,\n    \"mean\": 0.5448,\n    \"min\": 0.2322,\n    \"max\": 0.9731,\n    \"total_records\": 6,\n    \"record_level_metrics\": [\n      {\n        \"answer_relevance\": 0.8572,\n        \"record_id\": \"bd753865-1c32-42ef-9ff8-1f0d104be838\"\n      },\n      {\n        \"answer_relevance\": 0.9731,\n        \"record_id\": \"1e2df015-0e05-407e-8c8b-85ca7d0645db\"\n      },\n      {\n        \"answer_relevance\": 0.3744,\n        \"record_id\": \"1883183f-602c-4898-98cb-9865ffcdd60c\"\n      },\n      {\n        \"answer_relevance\": 0.5719,\n        \"record_id\": \"d4c1308b-d9f0-4750-8272-ec5e1677ee08\"\n      },\n      {\n        \"answer_relevance\": 0.2602,\n        \"record_id\": \"52cef78c-38c1-4a5c-88dd-02655fcc389c\"\n      },\n      {\n        \"answer_relevance\": 0.2322,\n        \"record_id\": \"5796ddde-8527-4845-8753-e213e4352fd6\"\n      }\n    ]\n  },\n  \"faithfulness\": {\n    \"computation_tasks\": [\n      {\n        \"entity\": {\n          \"status\": {\n            \"state\": \"in_progress\"\n          }\n        },\n        \"metadata\": {\n          \"created_at\": \"2024-07-22T11:02:46.740325Z\",\n          \"created_by\": \"IBMid-060001K23P\",\n          \"id\": \"9b6d0231-f0f8-4c07-bced-cbd3129fc771\",\n          \"updated_at\": \"2024-07-22T11:02:46.740325Z\"\n        }\n      }\n    ]\n  }\n}\n", "name": "stdout"}]}, {"metadata": {}, "id": "f32268ba-56ec-43d6-a91d-97c9d59105b5", "cell_type": "markdown", "source": "## Step 7 - Display the results <a id=\"results\"></a>"}, {"metadata": {}, "id": "42dca741-bc78-4550-a5e7-cd33e068e562", "cell_type": "markdown", "source": "### Get metric results for all records"}, {"metadata": {}, "id": "9b4fb1f3-840b-43f9-9e0e-74597f29b0f0", "cell_type": "code", "source": "# Execute this cell only after the above faithulness metric computation tasks are complete\nresults_df = data.copy()\nfor k, v in final_results.items():\n    if v.get(\"record_level_metrics\"):\n        results_df[k] = [r.get(k) for r in v.get(\"record_level_metrics\")]\nresults_df", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "                                            context1  \\\n0  Last month, I announced our plan to supercharg...   \n1  So let\u2019s not wait any longer. Send it to my de...   \n2  My plan will cut the cost in half for most fam...   \n3  If you travel 20 miles east of Columbus, Ohio,...   \n4  So let\u2019s not wait any longer. Send it to my de...   \n5  So let\u2019s not wait any longer. Send it to my de...   \n\n                                            context2  \\\n0  For that purpose we\u2019ve mobilized American grou...   \n1  If you travel 20 miles east of Columbus, Ohio,...   \n2  We got more than 130 countries to agree on a g...   \n3  So let\u2019s not wait any longer. Send it to my de...   \n4  If you travel 20 miles east of Columbus, Ohio,...   \n5  If you travel 20 miles east of Columbus, Ohio,...   \n\n                                            context3  \\\n0  If you travel 20 miles east of Columbus, Ohio,...   \n1  When we use taxpayer dollars to rebuild Americ...   \n2  And unlike the $2 Trillion tax cut passed in t...   \n3  When we use taxpayer dollars to rebuild Americ...   \n4  When we use taxpayer dollars to rebuild Americ...   \n5  It is going to transform America and put us on...   \n\n                                            context4  \\\n0  But cancer from prolonged exposure to burn pit...   \n1  It is going to transform America and put us on...   \n2  We\u2019re going after the criminals who stole bill...   \n3  It is going to transform America and put us on...   \n4  As Ohio Senator Sherrod Brown says, \u201cIt\u2019s time...   \n5  Vice President Harris and I ran for office wit...   \n\n                                            question  \\\n0                                    What is ARPA-H?   \n1  What is the investment of Ford and GM to build...   \n2    What is the proposed tax rate for corporations?   \n3                      What is Intel going to build?   \n4  How many new manufacturing jobs are created la...   \n5  How many electric vehicle charging stations ar...   \n\n                                              answer  answer_relevance  \n0   ARPA-H is the Advanced Research Projects Agen...            0.8572  \n1   Ford is investing $11 billion to build electr...            0.9731  \n2   The proposed tax rate for corporations is a 1...            0.3744  \n3   Intel is going to build a $20 billion semicon...            0.5719  \n4   369,000 new manufacturing jobs are created la...            0.2602  \n5   The document does not provide information on ...            0.2322  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context1</th>\n      <th>context2</th>\n      <th>context3</th>\n      <th>context4</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>answer_relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last month, I announced our plan to supercharg...</td>\n      <td>For that purpose we\u2019ve mobilized American grou...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>But cancer from prolonged exposure to burn pit...</td>\n      <td>What is ARPA-H?</td>\n      <td>ARPA-H is the Advanced Research Projects Agen...</td>\n      <td>0.8572</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>When we use taxpayer dollars to rebuild Americ...</td>\n      <td>It is going to transform America and put us on...</td>\n      <td>What is the investment of Ford and GM to build...</td>\n      <td>Ford is investing $11 billion to build electr...</td>\n      <td>0.9731</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>My plan will cut the cost in half for most fam...</td>\n      <td>We got more than 130 countries to agree on a g...</td>\n      <td>And unlike the $2 Trillion tax cut passed in t...</td>\n      <td>We\u2019re going after the criminals who stole bill...</td>\n      <td>What is the proposed tax rate for corporations?</td>\n      <td>The proposed tax rate for corporations is a 1...</td>\n      <td>0.3744</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>When we use taxpayer dollars to rebuild Americ...</td>\n      <td>It is going to transform America and put us on...</td>\n      <td>What is Intel going to build?</td>\n      <td>Intel is going to build a $20 billion semicon...</td>\n      <td>0.5719</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>When we use taxpayer dollars to rebuild Americ...</td>\n      <td>As Ohio Senator Sherrod Brown says, \u201cIt\u2019s time...</td>\n      <td>How many new manufacturing jobs are created la...</td>\n      <td>369,000 new manufacturing jobs are created la...</td>\n      <td>0.2602</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>So let\u2019s not wait any longer. Send it to my de...</td>\n      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n      <td>It is going to transform America and put us on...</td>\n      <td>Vice President Harris and I ran for office wit...</td>\n      <td>How many electric vehicle charging stations ar...</td>\n      <td>The document does not provide information on ...</td>\n      <td>0.2322</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "id": "638f295c-4bb0-489b-b55e-204d44cc34c3", "cell_type": "markdown", "source": "### Show attributions for the first record\n\nAttributions are the most important sentences in the context that contributed to the faithfulness score."}, {"metadata": {}, "id": "79d7329c-5f8b-427b-9236-28fb795fb350", "cell_type": "code", "source": "record_idx = 0\nattributions, attribution_scores = [], []\nfor i in final_results.get(\"faithfulness\")[\"record_level_metrics\"][record_idx][\"faithfulness_attributions\"]:\n    for attr in i[\"attributions\"]:\n        attributions.extend(attr.get(\"feature_values\"))\n        attribution_scores.extend(attr.get(\"faithfulness_scores\"))\n\nattributions_df = pd.DataFrame({\"faithfulness attribution\": attributions, \"attribution score\": attribution_scores})\npd.set_option('display.max_colwidth', 0)\nattributions_df.sort_values(by=[\"attribution score\"], inplace=True, ascending=False)\nprint(\"Question: {}\".format(results_df[question_column][0]))\nprint(\"Answer: {}\".format(results_df[answer_column][0]))\nprint(\"Attributions: \")\nattributions_df", "execution_count": 22, "outputs": [{"output_type": "error", "ename": "KeyError", "evalue": "'record_level_metrics'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)", "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m record_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m attributions, attribution_scores \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfinal_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfaithfulness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecord_level_metrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[record_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaithfulness_attributions\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributions\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      5\u001b[0m         attributions\u001b[38;5;241m.\u001b[39mextend(attr\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_values\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n", "\u001b[0;31mKeyError\u001b[0m: 'record_level_metrics'"]}, {"output_type": "stream", "text": "Traceback (most recent call last):\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages/ipykernel/__main__.py\", line 4, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n    self.io_loop.start()\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/envs/Python-RT23.1/lib/python3.10/asyncio/base_events.py\", line 1894, in _run_once\n    handle = self._ready.popleft()\nIndexError: pop from an empty deque\n", "name": "stderr"}]}, {"metadata": {}, "id": "2f7a5d46-b78e-4945-878e-53dd4b5936ba", "cell_type": "markdown", "source": "Author: <a href=\"mailto:pvemulam@in.ibm.com\">Pratap Kishore Varma V</a>"}, {"metadata": {}, "id": "2cc84acc", "cell_type": "markdown", "source": "Copyright \u00a9 2024 IBM."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}